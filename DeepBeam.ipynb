{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "primary-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# core code for predicting the shear strength of RC deep beams\n",
    "# v 1.0\n",
    "# 2020-02-23\n",
    "\n",
    "# define some necessary packages\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib\n",
    "matplotlib.rcParams['mathtext.fontset']='stix'\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subject-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(true, pred):\n",
    "    diff = np.abs(np.array(true) - np.array(pred))\n",
    "    return np.mean(diff / true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blocked-change",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fc</th>\n",
       "      <th>b</th>\n",
       "      <th>h</th>\n",
       "      <th>a</th>\n",
       "      <th>h0</th>\n",
       "      <th>l0</th>\n",
       "      <th>a/h0</th>\n",
       "      <th>l0/h</th>\n",
       "      <th>sv</th>\n",
       "      <th>fyv</th>\n",
       "      <th>rv</th>\n",
       "      <th>sh</th>\n",
       "      <th>fyh</th>\n",
       "      <th>rh</th>\n",
       "      <th>fy</th>\n",
       "      <th>ry</th>\n",
       "      <th>V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.45</td>\n",
       "      <td>100.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>690.11</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1.82</td>\n",
       "      <td>249.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.10</td>\n",
       "      <td>130.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.57</td>\n",
       "      <td>362.82</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>101.25</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>347.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.70</td>\n",
       "      <td>130.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>500.00</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.57</td>\n",
       "      <td>362.82</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>101.25</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>284.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.20</td>\n",
       "      <td>76.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>470.00</td>\n",
       "      <td>762.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.50</td>\n",
       "      <td>76.00</td>\n",
       "      <td>279.9</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>286.8</td>\n",
       "      <td>0.79</td>\n",
       "      <td>190.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>462.96</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>5.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>375.2</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>504.8</td>\n",
       "      <td>1.23</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fc      b      h       a      h0      l0  a/h0  l0/h      sv    fyv  \\\n",
       "0  21.45  100.0  750.0   500.0  690.11  1500.0  0.72  2.00    0.00    0.0   \n",
       "1  49.10  130.0  560.0   625.0  500.00  2000.0  1.25  3.57  362.82  410.0   \n",
       "2  23.70  130.0  560.0   425.0  500.00  2000.0  0.85  3.57  362.82  410.0   \n",
       "3  21.20   76.0  508.0   254.0  470.00   762.0  0.54  1.50   76.00  279.9   \n",
       "4  42.80  110.0  500.0  1250.0  462.96  2500.0  2.70  5.00  300.00  375.2   \n",
       "\n",
       "     rv      sh    fyh    rh     fy    ry       V  \n",
       "0  0.00    0.00    0.0  0.00  210.0  1.82  249.90  \n",
       "1  0.12  101.25  410.0  0.43  410.0  1.56  347.10  \n",
       "2  0.12  101.25  410.0  0.43  410.0  1.56  284.05  \n",
       "3  2.45    0.00    0.0  0.00  286.8  0.79  190.00  \n",
       "4  0.48    0.00    0.0  0.00  504.8  1.23  105.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the full data set\n",
    "# dataset=np.loadtxt('DeepBeam2.csv',delimiter=\",\")\n",
    "dataset = pd.read_excel('C:/Users/WjW/Desktop/2021.2.1/DeepBeam2.xlsx', sheet_name='DeepBeam2')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "educational-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the original input variables from the database\n",
    "fc = dataset.loc[:, 'fc']\n",
    "b = dataset.loc[:, 'b']\n",
    "h = dataset.loc[:, 'h']\n",
    "a = dataset.loc[:, 'a']\n",
    "h0 = dataset.loc[:, 'h0']\n",
    "l0 = dataset.loc[:, 'l0']\n",
    "sv = dataset.loc[:, 'sv']\n",
    "fyv = dataset.loc[:, 'fyv']\n",
    "rv = dataset.loc[:, 'rv']\n",
    "sh = dataset.loc[:, 'sh']\n",
    "fyh = dataset.loc[:, 'fyh']\n",
    "rh = dataset.loc[:, 'rh']\n",
    "fy = dataset.loc[:, 'fy']\n",
    "ry = dataset.loc[:, 'ry']\n",
    "V = dataset.loc[:, 'V']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "grand-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 16)\n",
      "[[2.145e+01 1.000e+02 7.500e+02 ... 0.000e+00 2.100e+02 1.820e+00]\n",
      " [4.910e+01 1.300e+02 5.600e+02 ... 4.300e-01 4.100e+02 1.560e+00]\n",
      " [2.370e+01 1.300e+02 5.600e+02 ... 4.300e-01 4.100e+02 1.560e+00]\n",
      " ...\n",
      " [5.120e+01 1.100e+02 5.000e+02 ... 0.000e+00 5.048e+02 1.230e+00]\n",
      " [2.757e+01 1.000e+02 9.000e+02 ... 3.500e-01 3.340e+02 2.700e-01]\n",
      " [4.910e+01 1.300e+02 5.600e+02 ... 4.300e-01 4.100e+02 1.560e+00]]\n"
     ]
    }
   ],
   "source": [
    "# constructing 6 new normalized dimensionless input variables\n",
    "X = np.zeros(shape=(272,16))\n",
    "X[:, 0] = fc\n",
    "X[:, 1] = b\n",
    "X[:, 2] = h\n",
    "X[:, 3] = a\n",
    "X[:, 4] = h0\n",
    "X[:, 5] = l0\n",
    "X[:, 6] = a/h0\n",
    "X[:, 7] = l0/h\n",
    "X[:, 8] = sv\n",
    "X[:, 9] = fyv\n",
    "X[:, 10] = rv\n",
    "X[:, 11] = sh\n",
    "X[:, 12] = fyh\n",
    "X[:, 13] = rh\n",
    "X[:, 14] = fy\n",
    "X[:, 15] = ry\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reverse-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272,)\n"
     ]
    }
   ],
   "source": [
    "# defining the output, i.e., the shear strength of the corroded beam\n",
    "y = V\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "previous-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data sets\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "infectious-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323957470901249\n"
     ]
    }
   ],
   "source": [
    "# split the training-testing set into 10 folds\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n",
    "\n",
    "# define training algorithms\n",
    "# RF\n",
    "regr_1 = RandomForestRegressor(n_estimators=80,max_depth=8,max_leaf_nodes=250,min_samples_leaf=2,min_samples_split=5,bootstrap= True,random_state=0,max_features=12)\n",
    "\n",
    "# # GBRT\n",
    "regr_2 = GradientBoostingRegressor(n_estimators=500, learning_rate=0.02,max_depth=8,min_samples_leaf=2,min_samples_split=2, random_state=0, loss='ls')\n",
    "\n",
    "# # AdaBoost\n",
    "regr_3 = AdaBoostRegressor (tree.DecisionTreeRegressor(max_depth=8,min_samples_split=3,min_samples_leaf=2,max_leaf_nodes=15,criterion='mse'),n_estimators=400, learning_rate=0.1, random_state=0)\n",
    "\n",
    "# XGB\n",
    "regr_4 = xgb.XGBRegressor (max_depth=8, learning_rate=0.02, n_estimators=600, colsample_bytree=1, subsample=0.69,  gamma=0, random_state=0)\n",
    "\n",
    "#DT\n",
    "regr_5 = DecisionTreeRegressor(max_depth=20,max_leaf_nodes=80,min_samples_leaf=2,min_samples_split=12,random_state=0)\n",
    "\n",
    "# #SVM\n",
    "regr_6 = svm.SVR(kernel='rbf', C=1500, gamma=0.04,coef0=0)\n",
    "\n",
    "#ANN\n",
    "# regr_7 = MLPRegressor(hidden_layer_sizes=(5,), solver='lbfgs', alpha=0.001, random_state=0, epsilon=1e-08)\n",
    "regr_7 = MLPRegressor(hidden_layer_sizes=(8,), solver='lbfgs', random_state=0, max_iter=500)\n",
    "###\n",
    "regr = regr_3\n",
    "predicted = cross_val_predict (regr, X_train, y_train, cv=10)\n",
    "scores = cross_val_score(regr, X_train, y_train, cv=10, scoring='r2', n_jobs = -1)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "regulated-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training RMSE: 29.949584429469926 MAE: 25.089927262309313 MAPE: 0.12057827176551532 R2: 0.971616560270381\n",
      " Testing RMSE: 52.241340551507385 MAE: 35.653125374667205 MAPE: 0.12718930830114877 R2: 0.9225905083293233\n"
     ]
    }
   ],
   "source": [
    "# validate the predictive model\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "Z = regr.predict(X_train)\n",
    "Z1 = regr.predict(X_test)\n",
    "\n",
    "print(\" Training RMSE:\", np.sqrt(mean_squared_error(y_train, Z)), \"MAE:\", mean_absolute_error(y_train, Z), \"MAPE:\", MAPE(y_train, Z), \"R2:\", r2_score(y_train, Z))\n",
    "print(\" Testing RMSE:\", np.sqrt(mean_squared_error(y_test, Z1)), \"MAE:\", mean_absolute_error(y_test, Z1), \"MAPE:\", MAPE(y_test, Z1), \"R2:\", r2_score(y_test, Z1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## -------------------- step 1\n",
    "### plot the results \n",
    "# xx = np.linspace(0, 1400, 100)\n",
    "# yy = xx\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(xx, yy, c='k', linewidth=2)\n",
    "# plt.scatter(y_train, Z, marker='s')\n",
    "# plt.scatter(y_test, Z1, marker='o')\n",
    "# plt.grid()\n",
    "\n",
    "# plt.tick_params (axis='both',which='major',labelsize=14)\n",
    "# plt.yticks(size = 14)\n",
    "# plt.xticks(size = 14)\n",
    "# font1 = {'family' : 'sans-serif', 'weight' : 'normal', 'size' :16,}\n",
    "# plt.axis('tight')\n",
    "# plt.xlabel('Tested shear strength (kN)', font1)\n",
    "# plt.ylabel('Predicted shear strength (kN)', font1)\n",
    "# plt.xlim([-100, 1500])\n",
    "# plt.ylim([-100, 1500])\n",
    "# plt.legend(['y=x','Training set','Testing set'], loc = 'upper left', fontsize=14)\n",
    "# plt.savefig('Fig6d.eps', dpi=600, bbox_inches = 'tight', format='eps')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## -------------------- step 2\n",
    "### plot the accuracy of ML models\n",
    "\n",
    "# y_pre = regr.predict(X)\n",
    "# y_ture = dataset[0:, 16]\n",
    "\n",
    "# ratio = y_ture/y_pre\n",
    "\n",
    "# # plot the accuracy of experience models\n",
    "# dataset1=np.loadtxt('steel.csv',delimiter=\",\")\n",
    "# # ratio = dataset1[0:, 6]#GB\n",
    "# ratio = dataset1[0:, 7]#ACI\n",
    "# # ratio = dataset1[0:, 8]#CSA\n",
    "# # ratio = dataset1[0:, 9]#EC2EC2\n",
    "\n",
    "\n",
    "# mean = np.mean(ratio)\n",
    "# std = np.std(ratio, ddof=1)\n",
    "# xx = np.linspace(0, 3, 3)\n",
    "# yy = mean*np.ones(3)\n",
    "# yy1 = (mean+std)*np.ones(3)\n",
    "# yy2 = (mean-std)*np.ones(3)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(xx, yy, c='k', linewidth=2)\n",
    "# plt.plot(xx, yy1, c='b', ls='--', linewidth=2)\n",
    "# plt.plot(xx, yy2, c='b', ls='--', linewidth=2)\n",
    "\n",
    "# # sample = dataset[0:, 6]\n",
    "# sample = dataset1[0:, 0]\n",
    "# # sample = np.arange(1, len(ada_ratio)+1)dataset[0:, 0:16]\n",
    "# plt.scatter(sample, ratio, c='r', marker='o')\n",
    "\n",
    "# plt.grid()\n",
    "# plt.tick_params(axis='both',which='major',labelsize=14)\n",
    "# font1 = {'family' : 'sans-serif', 'weight' : 'normal', 'size' : 16,}\n",
    "# plt.axis('tight')\n",
    "# plt.xlabel('a/d ratio', font1)\n",
    "# plt.ylabel('Predict-to-test ratio', font1)\n",
    "# plt.ylim([0, 4])\n",
    "# plt.legend(['Mean','Mean+St.D.','Mean-St.D.','XGBoost'], loc = 'upper right', fontsize=12)\n",
    "\n",
    "\n",
    "# print(' mean :', mean, ' std :', std, ' COV :', std/mean)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## -------------------- step 3\n",
    "### plot the accuracy of ML models\n",
    "\n",
    "# data = pd.read_csv('DeepBeam2 - fea.csv')\n",
    "# x=[r'fc',r'b',r'h',r'a',r'h0',r'l0',r'a/h0',r'l0/h',r'sv',r'fyv',r'ρv',r'sh',r'fyh',r'ρh',r'fy',r'ρy']\n",
    "# X = data[x]\n",
    "# y = data['V']\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "# # train XGBoost model\n",
    "# model= xgb.XGBRegressor (max_depth=8, learning_rate=0.02, n_estimators=600, colsample_bytree=1, subsample=0.69,  gamma=0, random_state=0)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# # 10-fold cv results for hyper-parameter validation\n",
    "# scores = cross_val_score(model, X_train, y_train, cv=10, scoring='r2', n_jobs = -1)\n",
    "# print(scores.mean())\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# xgb.plot_importance(model, max_num_features=16, importance_type='weight', height=0.6)\n",
    "\n",
    "# # plot the feature imprtance\n",
    "# feature_names = [r'$f_c$',r'$b$',r'$h$',r'$a$',r'$h_0$',r'$l_0$',r'$a/h_0$',r'$l_0/h$',r'$s_v$',r'$f_{yv}$',r'$\\rho_v$',r'$s_h$',r'$f_{yh}$',r'$\\rho_h$',r'$f_y$',r'$\\rho_l$'] # 根据输入改\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# model.importance_type = 'weight'\n",
    "\n",
    "# feature_importance = model.feature_importances_\n",
    "\n",
    "# # feature_importance = model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# # perform permutation importance\n",
    "# # results = permutation_importance(model, X, y, scoring='neg_mean_squared_error')\n",
    "# # get importance\n",
    "# # feature_importance = results.importances_mean\n",
    "\n",
    "# print(feature_importance)\n",
    "\n",
    "# feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "# sorted_idx = np.argsort(feature_importance)\n",
    "# pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "# plt.barh (pos, feature_importance[sorted_idx], 0.6, align='center',)\n",
    "# plt.yticks(pos, np.array(feature_names)[sorted_idx],style='italic')\n",
    "# plt.yticks(rotation=360)\n",
    "\n",
    "# for x, y in enumerate(feature_importance[sorted_idx]):\n",
    "# \tplt.text(y + 0.5, x + 0.3, '%s' % '{:.1%}'.format(y/100))\n",
    "\n",
    "# font1 = {'family' : 'sans-serif', 'weight' : 'normal', 'size' : 14,}\n",
    "# plt.axis('tight')\n",
    "\n",
    "# plt.tick_params(axis='both',which='major',labelsize=14)\n",
    "# plt.yticks(size = 14)\n",
    "# plt.xticks(size = 14)\n",
    "# plt.xlabel('Relative importance ($\\%$)', font1)\n",
    "# plt.ylabel('Features', font1)\n",
    "# plt.title('Feature importance', font1)\n",
    "# # plt.xlim([0, 110])\n",
    "\n",
    "# plt.grid()\n",
    "\n",
    "# plt.savefig('Fig6.eps', dpi=600, bbox_inches = 'tight', format='eps')\n",
    "# # plt.tight_layout(pad=3, w_pad=1.0, h_pad=1.0)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## -------------------- step 4\n",
    "### plot the partial dependence of ML models\n",
    "\n",
    "# def plot_curve(X, Y, x_range, x_size):\n",
    "#     #X represents fc values, Y represents predicted PHL ratios \n",
    "#     #x_range=[min,max],xsize represents the interval; exp.xlim=[20,180] xsize=20\n",
    "\n",
    "#     xmin, xmax = x_range\n",
    "\n",
    "#     plx = np.linspace(xmin+x_size/2, xmax-x_size/2, (xmax-xmin-x_size)/x_size+1)\n",
    "#     plm = np.zeros(len(plx))\n",
    "#     pls = np.zeros(len(plx))\n",
    "\n",
    "#     for i in range(len(plx)):\n",
    "#         temp=[]\n",
    "#         for j in range(len(X)):        \n",
    "#             if X[j] >= plx[i]-x_size/2 and X[j] < plx[i]+x_size/2:\n",
    "#                 temp.append(Y[j])\n",
    "#         if len(temp) == 0:\n",
    "#             plm[i]=plm[i-1]\n",
    "#             pls[i]=pls[i-1]\n",
    "#         elif len(temp) == 1:\n",
    "#             plm[i]=temp[0]\n",
    "#             pls[i]=pls[i-1]\n",
    "#         else:\n",
    "#             plm[i] = np.mean(temp)\n",
    "#             pls[i] = np.std(temp,ddof=1)\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(plx,plm,'o-',color='r',label=\"Mean value\")\n",
    "#     plt.fill_between(plx,plm-pls,plm+pls,alpha=0.1,color='r')\n",
    "#     plt.tick_params(axis = 'both', which = 'major', labelsize = 16)\n",
    "#     plt.yticks(fontproperties = 'Times New Roman', size = 16)\n",
    "#     plt.xticks(fontproperties = 'Times New Roman', size = 16)\n",
    "#     font1 = {'family' : 'times new roman', 'weight' : 'normal', 'size' : 18,}\n",
    "#     font2 = {'family' : 'times new roman', 'weight' : 'normal', 'size' : 14}\n",
    "\n",
    "#     plt.axis('tight')\n",
    "#     plt.ylabel('Ground truth/predited ratio',font1)\n",
    "#     plt.xlim(x_range)\n",
    "#     plt.ylim([0., 1.4])\n",
    "#     plt.legend(loc = 'lower right', fontsize=14, prop=font2)\n",
    "\n",
    "# #example  \n",
    "# plot_curve(X_inp[:,4], ada_ratio, [20,180], 25)\n",
    "# plt.xlabel('$f_c$ (MPa)',font1)\n",
    "# plt.savefig('Fig12a.pdf', dpi=600, bbox_inches = 'tight', format='pdf')\n",
    "\n",
    "# plot_curve(X_inp[:,11], ada_ratio, [0,0.8], 0.1)\n",
    "# plt.xlabel('$n$',font1)\n",
    "# plt.savefig('Fig12b.pdf', dpi=600, bbox_inches = 'tight', format='pdf')\n",
    "\n",
    "# plot_curve(X_inp[:,6], ada_ratio, [0.5,6.5], 0.7)\n",
    "# plt.xlabel(r'$\\rho_s$ (\\%)',font1)\n",
    "# plt.savefig('Fig12c.pdf', dpi=600, bbox_inches = 'tight', format='pdf')\n",
    "\n",
    "# plot_curve(X_inp[:,7], ada_ratio, [320,580], 50)\n",
    "# plt.xlabel('$f_y$ (MPa)',font1)\n",
    "# plt.savefig('Fig12d.pdf', dpi=600, bbox_inches = 'tight', format='pdf')\n",
    "\n",
    "# # end\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# data = pd.read_csv('DeepBeam2 - fea.csv')\n",
    "# data.info()\n",
    "\n",
    "# X = data.loc[:, data.columns != 'V']\n",
    "# y = data['V']\n",
    "\n",
    "# x = ['fc','b','h','a','h0','l0','a/h0','l0/h','sv','fyv','ρv','sh','fyh','ρh','fy','ρy']\n",
    "# # x = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15']\n",
    "# # X = data[x]\n",
    "# # y = data['V']\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "# # train XGBoost model\n",
    "# model = xgb.XGBRegressor(max_depth=8, learning_rate=0.02, n_estimators=600, colsample_bytree=1, subsample=0.69,  gamma=0, random_state=0)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Z = model.predict(X_train)\n",
    "# Z1 = model.predict(X_test)\n",
    "\n",
    "# print(\" Training RMSE:\", np.sqrt(mean_squared_error(y_train, Z)), \"MAE:\", mean_absolute_error(y_train, Z), \"MAPE:\", MAPE(y_train, Z), \"R2:\", r2_score(y_train, Z))\n",
    "# print(\" Testing RMSE:\", np.sqrt(mean_squared_error(y_test, Z1)), \"MAE:\", mean_absolute_error(y_test, Z1), \"MAPE:\", MAPE(y_test, Z1), \"R2:\", r2_score(y_test, Z1))\n",
    "\n",
    "# # plot_partial_dependence (model, X_train, features=x, feature_names=x,\n",
    "# #                         n_jobs=3, grid_resolution=10)\n",
    "\n",
    "\n",
    "# print(x)\n",
    "# data.head()\n",
    "\n",
    "\n",
    "\n",
    "# from pdpbox import pdp\n",
    "\n",
    "\n",
    "# # feature = f1\n",
    "# pdp_goals = pdp.pdp_isolate (model = model, dataset = data, model_features = x, feature = 'b')\n",
    "\n",
    "# pdp.pdp_plot(pdp_goals, 'b')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
